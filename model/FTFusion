import torch
import torch.nn as nn

from layers.Time_Domain_Branch import TimeDomainBranch
from layers.Frequency_Domain_Branch import FrequencyDomainBranch
from layers.Cross_Domain_Fusion import CrossDomainFusion
from layers.RevIN import RevIN

class FTFusion(nn.Module):
    """Parallel Time-Frequency Domain SeqScale Architecture"""
    def __init__(self, configs):
        super(FTFusion, self).__init__()
        self.seq_len = configs.seq_len
        self.pred_len = configs.pred_len
        self.enc_in = configs.enc_in
        self.c_out = configs.c_out
        self.kernel_sizes = configs.kernel_sizes
        self.individual = configs.individual
        self.dropout = configs.dropout
        
        # Frequency domain parameters
        self.use_parallel_domains = configs.use_parallel_domains
        self.n_freq_bands = configs.n_freq_bands
        
        # Input normalization
        self.revin = RevIN(self.enc_in)
        
        if self.use_parallel_domains:
            # Parallel time and frequency branches
            self.time_branch = TimeDomainBranch(
                seq_len=self.seq_len,
                pred_len=self.pred_len,
                n_features=self.enc_in,
                kernel_sizes=self.kernel_sizes,
                individual=self.individual,
                dropout=self.dropout
            )
            
            self.freq_branch = FrequencyDomainBranch(
                seq_len=self.seq_len,
                pred_len=self.pred_len,
                n_features=self.enc_in,
                n_freq_bands=self.n_freq_bands,
                dropout=self.dropout
            )
            
            # Cross-domain fusion
            self.fusion = CrossDomainFusion(
                pred_len=self.pred_len,
                n_features=self.enc_in,
                dropout=self.dropout
            )
        else:
            # Fallback to simple time domain processing
            self.time_branch = TimeDomainBranch(
                seq_len=self.seq_len,
                pred_len=self.pred_len,
                n_features=self.enc_in,
                kernel_sizes=self.kernel_sizes,
                individual=self.individual,
                dropout=self.dropout
            )
        
        # Output projection
        if self.enc_in != self.c_out:
            self.output_projection = nn.Linear(self.enc_in, self.c_out)
        else:
            self.output_projection = nn.Identity()
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Args:
            x: [batch_size, seq_len, enc_in]
        Returns:
            output: [batch_size, pred_len, c_out]
        """
        # Normalize input
        x_norm = self.revin(x, mode='norm')
        
        if self.use_parallel_domains:
            # Parallel processing
            time_output = self.time_branch(x_norm)  # [batch_size, pred_len, enc_in]
            freq_output, periodicity_scores = self.freq_branch(x_norm)  # [batch_size, pred_len, enc_in], [batch_size, enc_in]
            
            # Cross-domain fusion
            fused_output = self.fusion(time_output, freq_output, periodicity_scores)
        else:
            # Time domain only
            fused_output = self.time_branch(x_norm)
        
        # Output projection
        output = self.output_projection(fused_output)
        
        # Denormalize
        if output.shape[-1] == x.shape[-1]:
            output = self.revin(output, mode='denorm')
        
        return output
